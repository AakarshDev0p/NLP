{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AakarshDev0p/NLP/blob/main/2403A52262_NLP_Assignment_8_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-00",
      "metadata": {
        "id": "cell-00"
      },
      "source": [
        "# **Corpus**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-01",
      "metadata": {
        "id": "cell-01"
      },
      "outputs": [],
      "source": [
        "D1: \"I am pursuing a Bachelor of Technology in Computer Science at SR University.\"\n",
        "\n",
        "D2: \"My curriculum includes advanced topics in programming and machine learning.\"\n",
        "\n",
        "D3: \"After completing my intermediate studies in MPC, I developed a strong interest in technology.\"\n",
        "\n",
        "D4: \"My ultimate goal is to become a successful software engineer.\"\n",
        "\n",
        "D5: \"I am deeply invested in learning new programming languages and data structures.\"\n",
        "\n",
        "D6: \"Machine learning applications fascinate me, especially in natural language processing.\"\n",
        "\n",
        "D7: \"I aspire to contribute to innovative software solutions in the future.\"\n",
        "\n",
        "D8: \"My educational journey has been focused on building a strong foundation in computer science.\"\n",
        "\n",
        "D9: \"The university environment at SR has provided excellent learning opportunities.\"\n",
        "\n",
        "D10: \"I am eager to apply my skills to real-world challenges in the tech industry.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-02",
      "metadata": {
        "id": "cell-02"
      },
      "source": [
        "# **Uni Gram Counts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-03",
        "outputId": "9e7cf93d-609c-4885-d165-be9889485d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "in: 9\n",
            "i: 5\n",
            "my: 5\n",
            "to: 5\n",
            "a: 4\n",
            "am: 3\n",
            "learning: 3\n",
            "the: 3\n",
            "computer: 2\n",
            "at: 2\n",
            "sr: 2\n",
            "programming: 2\n",
            "and: 2\n",
            "machine: 2\n",
            "strong: 2\n",
            "software: 2\n",
            "has: 2\n",
            "pursuing: 1\n",
            "bachelor: 1\n",
            "of: 1\n",
            "technology: 1\n",
            "science: 1\n",
            "university.: 1\n",
            "curriculum: 1\n",
            "includes: 1\n",
            "advanced: 1\n",
            "topics: 1\n",
            "learning.: 1\n",
            "after: 1\n",
            "completing: 1\n",
            "intermediate: 1\n",
            "studies: 1\n",
            "mpc,: 1\n",
            "developed: 1\n",
            "interest: 1\n",
            "technology.: 1\n",
            "ultimate: 1\n",
            "goal: 1\n",
            "is: 1\n",
            "become: 1\n",
            "successful: 1\n",
            "engineer.: 1\n",
            "deeply: 1\n",
            "invested: 1\n",
            "new: 1\n",
            "languages: 1\n",
            "data: 1\n",
            "structures.: 1\n",
            "applications: 1\n",
            "fascinate: 1\n",
            "me,: 1\n",
            "especially: 1\n",
            "natural: 1\n",
            "language: 1\n",
            "processing.: 1\n",
            "aspire: 1\n",
            "contribute: 1\n",
            "innovative: 1\n",
            "solutions: 1\n",
            "future.: 1\n",
            "educational: 1\n",
            "journey: 1\n",
            "been: 1\n",
            "focused: 1\n",
            "on: 1\n",
            "building: 1\n",
            "foundation: 1\n",
            "science.: 1\n",
            "university: 1\n",
            "environment: 1\n",
            "provided: 1\n",
            "excellent: 1\n",
            "opportunities.: 1\n",
            "eager: 1\n",
            "apply: 1\n",
            "skills: 1\n",
            "real-world: 1\n",
            "challenges: 1\n",
            "tech: 1\n",
            "industry.: 1\n",
            "Vocabulary Size= 80\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "\n",
        "D1: \"I am pursuing a Bachelor of Technology in Computer Science at SR University.\"\n",
        "D2: \"My curriculum includes advanced topics in programming and machine learning.\"\n",
        "D3: \"After completing my intermediate studies in MPC, I developed a strong interest in technology.\"\n",
        "D4: \"My ultimate goal is to become a successful software engineer.\"\n",
        "D5: \"I am deeply invested in learning new programming languages and data structures.\"\n",
        "D6: \"Machine learning applications fascinate me, especially in natural language processing.\"\n",
        "D7: \"I aspire to contribute to innovative software solutions in the future.\"\n",
        "D8: \"My educational journey has been focused on building a strong foundation in computer science.\"\n",
        "D9: \"The university environment at SR has provided excellent learning opportunities.\"\n",
        "D10: \"I am eager to apply my skills to real-world challenges in the tech industry.\"\n",
        "\n",
        "D1_content  = \"I am pursuing a Bachelor of Technology in Computer Science at SR University.\"\n",
        "D2_content  = \"My curriculum includes advanced topics in programming and machine learning.\"\n",
        "D3_content  = \"After completing my intermediate studies in MPC, I developed a strong interest in technology.\"\n",
        "D4_content  = \"My ultimate goal is to become a successful software engineer.\"\n",
        "D5_content  = \"I am deeply invested in learning new programming languages and data structures.\"\n",
        "D6_content  = \"Machine learning applications fascinate me, especially in natural language processing.\"\n",
        "D7_content  = \"I aspire to contribute to innovative software solutions in the future.\"\n",
        "D8_content  = \"My educational journey has been focused on building a strong foundation in computer science.\"\n",
        "D9_content  = \"The university environment at SR has provided excellent learning opportunities.\"\n",
        "D10_content = \"I am eager to apply my skills to real-world challenges in the tech industry.\"\n",
        "\n",
        "combined_text = f\"{D1_content} {D2_content} {D3_content} {D4_content} {D5_content} {D6_content} {D7_content} {D8_content} {D9_content} {D10_content}\"\n",
        "\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "V = len(unigram_counts)\n",
        "print(\"Vocabulary Size=\", V)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-04",
      "metadata": {
        "id": "cell-04"
      },
      "source": [
        "# **Bi-Gram Counts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-05",
        "outputId": "85a320bc-13f8-4d14-c4f6-e0e92adc3022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "i am: 3\n",
            "in computer: 2\n",
            "at sr: 2\n",
            "a strong: 2\n",
            "in the: 2\n",
            "am pursuing: 1\n",
            "pursuing a: 1\n",
            "a bachelor: 1\n",
            "bachelor of: 1\n",
            "of technology: 1\n",
            "technology in: 1\n",
            "computer science: 1\n",
            "science at: 1\n",
            "sr university.: 1\n",
            "university. my: 1\n",
            "my curriculum: 1\n",
            "curriculum includes: 1\n",
            "includes advanced: 1\n",
            "advanced topics: 1\n",
            "topics in: 1\n",
            "in programming: 1\n",
            "programming and: 1\n",
            "and machine: 1\n",
            "machine learning.: 1\n",
            "learning. after: 1\n",
            "after completing: 1\n",
            "completing my: 1\n",
            "my intermediate: 1\n",
            "intermediate studies: 1\n",
            "studies in: 1\n",
            "in mpc,: 1\n",
            "mpc, i: 1\n",
            "i developed: 1\n",
            "developed a: 1\n",
            "strong interest: 1\n",
            "interest in: 1\n",
            "in technology.: 1\n",
            "technology. my: 1\n",
            "my ultimate: 1\n",
            "ultimate goal: 1\n",
            "goal is: 1\n",
            "is to: 1\n",
            "to become: 1\n",
            "become a: 1\n",
            "a successful: 1\n",
            "successful software: 1\n",
            "software engineer.: 1\n",
            "engineer. i: 1\n",
            "am deeply: 1\n",
            "deeply invested: 1\n",
            "invested in: 1\n",
            "in learning: 1\n",
            "learning new: 1\n",
            "new programming: 1\n",
            "programming languages: 1\n",
            "languages and: 1\n",
            "and data: 1\n",
            "data structures.: 1\n",
            "structures. machine: 1\n",
            "machine learning: 1\n",
            "learning applications: 1\n",
            "applications fascinate: 1\n",
            "fascinate me,: 1\n",
            "me, especially: 1\n",
            "especially in: 1\n",
            "in natural: 1\n",
            "natural language: 1\n",
            "language processing.: 1\n",
            "processing. i: 1\n",
            "i aspire: 1\n",
            "aspire to: 1\n",
            "to contribute: 1\n",
            "contribute to: 1\n",
            "to innovative: 1\n",
            "innovative software: 1\n",
            "software solutions: 1\n",
            "solutions in: 1\n",
            "the future.: 1\n",
            "future. my: 1\n",
            "my educational: 1\n",
            "educational journey: 1\n",
            "journey has: 1\n",
            "has been: 1\n",
            "been focused: 1\n",
            "focused on: 1\n",
            "on building: 1\n",
            "building a: 1\n",
            "strong foundation: 1\n",
            "foundation in: 1\n",
            "computer science.: 1\n",
            "science. the: 1\n",
            "the university: 1\n",
            "university environment: 1\n",
            "environment at: 1\n",
            "sr has: 1\n",
            "has provided: 1\n",
            "provided excellent: 1\n",
            "excellent learning: 1\n",
            "learning opportunities.: 1\n",
            "opportunities. i: 1\n",
            "am eager: 1\n",
            "eager to: 1\n",
            "to apply: 1\n",
            "apply my: 1\n",
            "my skills: 1\n",
            "skills to: 1\n",
            "to real-world: 1\n",
            "real-world challenges: 1\n",
            "challenges in: 1\n",
            "the tech: 1\n",
            "tech industry.: 1\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "\n",
        "combined_text = f\"{D1_content} {D2_content} {D3_content} {D4_content} {D5_content} {D6_content} {D7_content} {D8_content} {D9_content} {D10_content}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-06",
      "metadata": {
        "id": "cell-06"
      },
      "source": [
        "### **Tri-Gram Counts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-07",
        "outputId": "f7930a52-e267-4e10-a317-be3bc6c6db96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "i am pursuing: 1\n",
            "am pursuing a: 1\n",
            "pursuing a bachelor: 1\n",
            "a bachelor of: 1\n",
            "bachelor of technology: 1\n",
            "of technology in: 1\n",
            "technology in computer: 1\n",
            "in computer science: 1\n",
            "computer science at: 1\n",
            "science at sr: 1\n",
            "at sr university.: 1\n",
            "sr university. my: 1\n",
            "university. my curriculum: 1\n",
            "my curriculum includes: 1\n",
            "curriculum includes advanced: 1\n",
            "includes advanced topics: 1\n",
            "advanced topics in: 1\n",
            "topics in programming: 1\n",
            "in programming and: 1\n",
            "programming and machine: 1\n",
            "and machine learning.: 1\n",
            "machine learning. after: 1\n",
            "learning. after completing: 1\n",
            "after completing my: 1\n",
            "completing my intermediate: 1\n",
            "my intermediate studies: 1\n",
            "intermediate studies in: 1\n",
            "studies in mpc,: 1\n",
            "in mpc, i: 1\n",
            "mpc, i developed: 1\n",
            "i developed a: 1\n",
            "developed a strong: 1\n",
            "a strong interest: 1\n",
            "strong interest in: 1\n",
            "interest in technology.: 1\n",
            "in technology. my: 1\n",
            "technology. my ultimate: 1\n",
            "my ultimate goal: 1\n",
            "ultimate goal is: 1\n",
            "goal is to: 1\n",
            "is to become: 1\n",
            "to become a: 1\n",
            "become a successful: 1\n",
            "a successful software: 1\n",
            "successful software engineer.: 1\n",
            "software engineer. i: 1\n",
            "engineer. i am: 1\n",
            "i am deeply: 1\n",
            "am deeply invested: 1\n",
            "deeply invested in: 1\n",
            "invested in learning: 1\n",
            "in learning new: 1\n",
            "learning new programming: 1\n",
            "new programming languages: 1\n",
            "programming languages and: 1\n",
            "languages and data: 1\n",
            "and data structures.: 1\n",
            "data structures. machine: 1\n",
            "structures. machine learning: 1\n",
            "machine learning applications: 1\n",
            "learning applications fascinate: 1\n",
            "applications fascinate me,: 1\n",
            "fascinate me, especially: 1\n",
            "me, especially in: 1\n",
            "especially in natural: 1\n",
            "in natural language: 1\n",
            "natural language processing.: 1\n",
            "language processing. i: 1\n",
            "processing. i aspire: 1\n",
            "i aspire to: 1\n",
            "aspire to contribute: 1\n",
            "to contribute to: 1\n",
            "contribute to innovative: 1\n",
            "to innovative software: 1\n",
            "innovative software solutions: 1\n",
            "software solutions in: 1\n",
            "solutions in the: 1\n",
            "in the future.: 1\n",
            "the future. my: 1\n",
            "future. my educational: 1\n",
            "my educational journey: 1\n",
            "educational journey has: 1\n",
            "journey has been: 1\n",
            "has been focused: 1\n",
            "been focused on: 1\n",
            "focused on building: 1\n",
            "on building a: 1\n",
            "building a strong: 1\n",
            "a strong foundation: 1\n",
            "strong foundation in: 1\n",
            "foundation in computer: 1\n",
            "in computer science.: 1\n",
            "computer science. the: 1\n",
            "science. the university: 1\n",
            "the university environment: 1\n",
            "university environment at: 1\n",
            "environment at sr: 1\n",
            "at sr has: 1\n",
            "sr has provided: 1\n",
            "has provided excellent: 1\n",
            "provided excellent learning: 1\n",
            "excellent learning opportunities.: 1\n",
            "learning opportunities. i: 1\n",
            "opportunities. i am: 1\n",
            "i am eager: 1\n",
            "am eager to: 1\n",
            "eager to apply: 1\n",
            "to apply my: 1\n",
            "apply my skills: 1\n",
            "my skills to: 1\n",
            "skills to real-world: 1\n",
            "to real-world challenges: 1\n",
            "real-world challenges in: 1\n",
            "challenges in the: 1\n",
            "in the tech: 1\n",
            "the tech industry.: 1\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "\n",
        "combined_text = f\"{D1_content} {D2_content} {D3_content} {D4_content} {D5_content} {D6_content} {D7_content} {D8_content} {D9_content} {D10_content}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-08",
      "metadata": {
        "id": "cell-08"
      },
      "source": [
        "Next Word Prediction Using Bi-Gram Counts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-09",
        "outputId": "ef3970d5-4c94-440b-8078-2d9c0950f928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  pursuing is  0.3333333333333333\n",
            "probability of  deeply is  0.3333333333333333\n",
            "probability of  eager is  0.3333333333333333\n",
            "Given sequence: 'I am', predicted next word: 'pursuing'\n",
            "probability of  new is  0.3333333333333333\n",
            "probability of  applications is  0.3333333333333333\n",
            "probability of  opportunities. is  0.3333333333333333\n",
            "Given sequence: 'machine learning', predicted next word: 'new'\n",
            "Given sequence: 'software engineer', predicted next word: 'No bigram found starting with 'engineer'.'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ],
      "source": [
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"machine learning\"\n",
        "next_word2 = predict_next_word_bigram(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"software engineer\"\n",
        "next_word3 = predict_next_word_bigram(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {
        "id": "cell-10"
      },
      "source": [
        "# **Deployment of Bi-Gram Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-11",
        "outputId": "aed81a4c-b0f7-4cea-e93e-637192766548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textdeveloped a\n",
            "probability of  bachelor is  0.25\n",
            "probability of  strong is  0.5\n",
            "probability of  successful is  0.25\n",
            "Given sequence: 'developed a', predicted next word: 'strong'\n"
          ]
        }
      ],
      "source": [
        "ip_text = input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-12",
      "metadata": {
        "id": "cell-12"
      },
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-13",
        "outputId": "7f5b0857-e49d-42dc-8528-333d2819af39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  a is  1.0\n",
            "Given sequence: 'I am pursuing', predicted next word: 'a'\n",
            "probability of  fascinate is  1.0\n",
            "Given sequence: 'machine learning applications', predicted next word: 'fascinate'\n"
          ]
        }
      ],
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am pursuing\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"machine learning applications\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-14",
      "metadata": {
        "id": "cell-14"
      },
      "source": [
        "# **Deployment of Tri-Gram Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-15",
        "outputId": "452558ec-b404-4637-c332-d3247d761618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textam pursuing a \n",
            "probability of  bachelor is  1.0\n",
            "Given sequence: 'am pursuing a ', predicted next word: 'bachelor'\n"
          ]
        }
      ],
      "source": [
        "ip_text = input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {
        "id": "cell-16"
      },
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-17",
        "outputId": "f2b49cb5-8890-43b4-de0b-7b5d303c4674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of pursuing is  0.024096385542168676\n",
            "probability of deeply is  0.024096385542168676\n",
            "probability of eager is  0.024096385542168676\n",
            "Given sequence: 'I am', predicted next word: 'pursuing'\n",
            "probability of new is  0.024096385542168676\n",
            "probability of applications is  0.024096385542168676\n",
            "probability of opportunities. is  0.024096385542168676\n",
            "Given sequence: 'machine learning', predicted next word: 'new'\n",
            "Given sequence: 'software engineer', predicted next word: 'No bigram found starting with 'engineer'.'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ],
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count + 1) / (last_word_unigram_count + V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"machine learning\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"software engineer\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-18",
      "metadata": {
        "id": "cell-18"
      },
      "source": [
        "# **Deployment of Laplace Smoothening based Bi-Gram Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-19",
        "outputId": "96e3d6bb-4d00-47cd-8824-e44b21e61520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textinvested in\n",
            "probability of computer is  0.033707865168539325\n",
            "probability of programming is  0.02247191011235955\n",
            "probability of mpc, is  0.02247191011235955\n",
            "probability of technology. is  0.02247191011235955\n",
            "probability of learning is  0.02247191011235955\n",
            "probability of natural is  0.02247191011235955\n",
            "probability of the is  0.033707865168539325\n",
            "Given sequence: 'invested in', predicted next word: 'computer'\n"
          ]
        }
      ],
      "source": [
        "ip_text = input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-20",
      "metadata": {
        "id": "cell-20"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cell-21",
      "metadata": {
        "id": "cell-21"
      },
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts based on laplace smoothening**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-22",
        "outputId": "8c999931-7f5e-4ce5-8483-f306a65a617a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  a is  0.024691358024691357\n",
            "Given sequence: 'I am pursuing', predicted next word: 'a'\n",
            "probability of  fascinate is  0.024691358024691357\n",
            "Given sequence: 'machine learning applications', predicted next word: 'fascinate'\n"
          ]
        }
      ],
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count + 1) / (last_two_words_bigram_count + V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am pursuing\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"machine learning applications\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-23",
      "metadata": {
        "id": "cell-23"
      },
      "source": [
        "# **Deployment of Laplace Smoothening based Tri-Gram Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-24",
        "outputId": "ea8a4005-3daa-41b1-8f80-fc4d8da1c6bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textaspire to contribute\n",
            "probability of  to is  0.024691358024691357\n",
            "Given sequence: 'aspire to contribute', predicted next word: 'to'\n"
          ]
        }
      ],
      "source": [
        "ip_text = input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-25",
      "metadata": {
        "id": "cell-25"
      },
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts with Add - K Smoothening**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-26",
        "outputId": "1891ee20-2ee9-4b68-b58d-8288a4bbf17e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of pursuing is  0.03488372093023256\n",
            "probability of deeply is  0.03488372093023256\n",
            "probability of eager is  0.03488372093023256\n",
            "Given sequence: 'I am', predicted next word: 'pursuing'\n",
            "probability of new is  0.03488372093023256\n",
            "probability of applications is  0.03488372093023256\n",
            "probability of opportunities. is  0.03488372093023256\n",
            "Given sequence: 'machine learning', predicted next word: 'new'\n",
            "Given sequence: 'software engineer', predicted next word: 'No bigram found starting with 'engineer'.'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ],
      "source": [
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count + K) / (last_word_unigram_count + K * V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"machine learning\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"software engineer\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-27",
      "metadata": {
        "id": "cell-27"
      },
      "source": [
        "# **Deployment of Add-K Smoothening based Bi-Gram Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-28",
        "outputId": "5ec5c99a-8998-4920-e50e-105ed37b1d84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texthas been\n",
            "probability of focused is  0.036585365853658534\n",
            "Given sequence: 'has been', predicted next word: 'focused'\n"
          ]
        }
      ],
      "source": [
        "ip_text = input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_K(ip_text, bigram_counts, unigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-29",
      "metadata": {
        "id": "cell-29"
      },
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-30",
        "outputId": "3f07d21f-b050-447d-8e00-bc9f8a3d9308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  a is  0.036585365853658534\n",
            "Given sequence: 'I am pursuing', predicted next word: 'a'\n",
            "probability of  fascinate is  0.036585365853658534\n",
            "Given sequence: 'machine learning applications', predicted next word: 'fascinate'\n"
          ]
        }
      ],
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts, K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count + K) / (last_two_words_bigram_count + K * V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am pursuing\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"machine learning applications\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-31",
      "metadata": {
        "id": "cell-31"
      },
      "source": [
        "# **Deployment of Add-K Smoothening based Tri-Gram Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-32",
        "outputId": "c58a6448-bfec-4287-d653-7656228edb30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textgoal is to\n",
            "probability of  become is  0.036585365853658534\n",
            "Given sequence: 'goal is to', predicted next word: 'become'\n"
          ]
        }
      ],
      "source": [
        "ip_text = input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-33",
      "metadata": {
        "id": "cell-33"
      },
      "source": [
        "# **Thank You**"
      ]
    }
  ]
}